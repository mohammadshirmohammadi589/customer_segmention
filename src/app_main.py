import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
import warnings
warnings.filterwarnings('ignore')

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª CSS Ø³ÙØ§Ø±Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ø¸Ø§Ù‡Ø± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø®ÙˆØ§Ù†Ø§
st.markdown("""
    <style>
    /* Ø§Ø³ØªØ§ÛŒÙ„ Ú©Ù„ÛŒ */
    body {
        font-family: 'Vazir', sans-serif;
        background-color: #F5F7FA;
        color: #1A2E4A;
    }
    .stApp {
        background-color: #F5F7FA;
        color: #1A2E4A;
    }
    /* Ø§Ø³ØªØ§ÛŒÙ„ Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± */
    .css-1d391kg {
        background-color: #1A2E4A;
        color: #FFFFFF;
        font-family: 'Vazir', sans-serif;
    }
    .css-1d391kg h1, .css-1d391kg h2, .css-1d391kg h3 {
        color: #FFFFFF;
    }
    /* Ø§Ø³ØªØ§ÛŒÙ„ Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ */
    .stTitle {
        color: #1A2E4A;
        font-size: 2.5rem;
        font-weight: 700;
        text-align: right;
    }
    /* Ø§Ø³ØªØ§ÛŒÙ„ ØªØ¨â€ŒÙ‡Ø§ */
    .stTabs [data-baseweb="tab"] {
        background-color: #E8ECEF;
        color: #1A2E4A;
        font-weight: 500;
        border-radius: 8px;
        margin: 5px;
    }
    .stTabs [data-baseweb="tab"][aria-selected="true"] {
        background-color: #1A2E4A;
        color: #FFFFFF;
    }
    /* Ø§Ø³ØªØ§ÛŒÙ„ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ */
    .stButton>button {
        background-color: #00A8B5;
        color: #FFFFFF;
        border-radius: 8px;
        font-weight: 500;
        transition: all 0.3s ease;
    }
    .stButton>button:hover {
        background-color: #007B85;
        color: #FFFFFF;
    }
    /* Ø§Ø³ØªØ§ÛŒÙ„ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ */
    .stMetric {
        background-color: #FFFFFF;
        padding: 15px;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        color: #1A2E4A !important;
    }
    .stMetric label {
        color: #1A2E4A !important;
        font-weight: 600;
    }
    .stMetric .css-1x0d4go {
        color: #1A2E4A !important;
        font-size: 1.5rem;
        font-weight: 700;
    }
    /* Ø§Ø³ØªØ§ÛŒÙ„ Ø§Ú©Ø³Ù¾Ù†Ø¯Ø± */
    .stExpander {
        background-color: #FFFFFF;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        color: #1A2E4A;
    }
    /* Ø§Ø³ØªØ§ÛŒÙ„ Ù†ÙˆØ´ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ */
    .stMarkdown, .stText, .stDataFrame {
        color: #1A2E4A;
    }
    </style>
""", unsafe_allow_html=True)

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡
st.set_page_config(
    page_title="ğŸ¯ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ØªØ­Ù„ÛŒÙ„ RFM Ùˆ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ
st.title("ğŸ¯ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù‡ÙˆØ´Ù…Ù†Ø¯ ØªØ­Ù„ÛŒÙ„ RFM Ùˆ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†")
st.markdown("""
**Ø§Ù…Ú©Ø§Ù†Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡:**
- âœ¨ ØªØ­Ù„ÛŒÙ„ RFM Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ØªÙ†Ø¸ÛŒÙ…
- ğŸ“Š Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ K-Means
- ğŸ¯ ÙˆÛŒÚ˜ÙˆØ§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ ØªØ¹Ø§Ù…Ù„ÛŒ
- ğŸ’¾ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†ØªØ§ÛŒØ¬ Ùˆ Ú¯Ø²Ø§Ø±Ø´Ø§Øª
- âš¡ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯
""")
st.markdown("---")

# ================== Ø¨Ø®Ø´ Û±: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ ==================
st.sidebar.header("ğŸ“¤ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡")

def create_sample_data():
    """Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ³Øª"""
    np.random.seed(42)
    n_customers = 1000
    data = {
        'CustomerID': [f'CUST_{i:04d}' for i in range(1, n_customers + 1)],
        'Recency': np.random.randint(1, 365, n_customers),
        'Frequency': np.random.randint(1, 50, n_customers),
        'Monetary': np.random.randint(1000, 50000, n_customers),
        'LastPurchaseDate': pd.date_range('2023-01-01', periods=n_customers, freq='D')
    }
    return pd.DataFrame(data)

uploaded_file = st.sidebar.file_uploader(
    "ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ (CSV ÛŒØ§ Excel)",
    type=['csv', 'xlsx', 'xls'],
    help="Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù…: CustomerID, Recency, Frequency, Monetary"
)

if uploaded_file is not None:
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
        st.sidebar.success("âœ… ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯!")
    except Exception as e:
        st.sidebar.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„: {e}")
        df = create_sample_data()
        st.sidebar.info("â„¹ï¸ Ø§Ø² Ø¯Ø§Ø¯Ù‡ Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
else:
    df = create_sample_data()
    st.sidebar.info("â„¹ï¸ Ø§Ø² Ø¯Ø§Ø¯Ù‡ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯")

# Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù…
with st.expander("ğŸ“Š Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù…"):
    st.dataframe(df.head(), use_container_width=True)
    st.write(f"ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù†: {len(df):,}")

# Ø¨Ø±Ø±Ø³ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
st.sidebar.header("ğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§")
st.sidebar.write("Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:", df.columns.tolist())

if 'Recency' not in df.columns:
    st.sidebar.warning("âŒ Ø³ØªÙˆÙ† Recency Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯! Ø¯Ø± Ø­Ø§Ù„ Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø¯Ù‡ Ù†Ù…ÙˆÙ†Ù‡...")
    def create_correct_sample_data():
        np.random.seed(42)
        n_customers = 500
        data = {
            'CustomerID': [f'CUST_{i:04d}' for i in range(1, n_customers + 1)],
            'Recency': np.random.randint(1, 365, n_customers),
            'Frequency': np.random.randint(1, 50, n_customers),
            'Monetary': np.random.randint(1000, 50000, n_customers)
        }
        return pd.DataFrame(data)
    df = create_correct_sample_data()
    st.sidebar.success("âœ… Ø¯Ø§Ø¯Ù‡ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØµØ­ÛŒØ­ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")

st.sidebar.success("âœ… Ø³ØªÙˆÙ† Recency ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯")

# ================== Ø¨Ø®Ø´ Û²: ØªÙ†Ø¸ÛŒÙ…Ø§Øª RFM ==================
st.sidebar.header("âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªØ­Ù„ÛŒÙ„ RFM")
st.sidebar.subheader("ğŸ“Š Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ú†Ø§Ø±Ú©â€ŒÙ‡Ø§")

r_q1 = st.sidebar.slider("Ú†Ø§Ø±Ú© Ø§ÙˆÙ„ Recency", 0, 365, 17, 1)
r_q2 = st.sidebar.slider("Ú†Ø§Ø±Ú© Ø¯ÙˆÙ… Recency", 0, 365, 49, 1)
r_q3 = st.sidebar.slider("Ú†Ø§Ø±Ú© Ø³ÙˆÙ… Recency", 0, 365, 134, 1)

f_q1 = st.sidebar.slider("Ú†Ø§Ø±Ú© Ø§ÙˆÙ„ Frequency", 0, 100, 17, 1)
f_q2 = st.sidebar.slider("Ú†Ø§Ø±Ú© Ø¯ÙˆÙ… Frequency", 0, 200, 40, 1)
f_q3 = st.sidebar.slider("Ú†Ø§Ø±Ú© Ø³ÙˆÙ… Frequency", 0, 500, 97, 1)

m_q1 = st.sidebar.slider("Ú†Ø§Ø±Ú© Ø§ÙˆÙ„ Monetary", 0, 5000, 296, 10)
m_q2 = st.sidebar.slider("Ú†Ø§Ø±Ú© Ø¯ÙˆÙ… Monetary", 0, 10000, 642, 10)
m_q3 = st.sidebar.slider("Ú†Ø§Ø±Ú© Ø³ÙˆÙ… Monetary", 0, 20000, 1554, 10)

# ================== Ø¨Ø®Ø´ Û³: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø²Ø§Øª RFM ==================
def calculate_rfm_scores(data, r_params, f_params, m_params):
    df = data.copy()
    def r_score(x):
        if pd.isna(x): return 1
        if x <= r_params[0]: return 4
        elif x <= r_params[1]: return 3
        elif x <= r_params[2]: return 2
        else: return 1
    def fm_score(x, params):
        if pd.isna(x): return 1
        if x <= params[0]: return 1
        elif x <= params[1]: return 2
        elif x <= params[2]: return 3
        else: return 4
    df['R_Score'] = df['Recency'].apply(r_score)
    df['F_Score'] = df['Frequency'].apply(fm_score, args=(f_params,))
    df['M_Score'] = df['Monetary'].apply(fm_score, args=(m_params,))
    df['RFM_Score'] = df['R_Score'].astype(str) + df['F_Score'].astype(str) + df['M_Score'].astype(str)
    return df

r_params = [r_q1, r_q2, r_q3]
f_params = [f_q1, f_q2, f_q3]
m_params = [m_q1, m_q2, m_q3]

rfm_df = calculate_rfm_scores(df, r_params, f_params, m_params)

# ================== Ø¨Ø®Ø´ Û´: Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ==================
st.sidebar.header("ğŸ¯ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ")

n_clusters = st.sidebar.slider(
    "ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§",
    min_value=2, max_value=8, value=4, step=1
)

max_iter = st.sidebar.slider(
    "ØªØ¹Ø¯Ø§Ø¯ ØªÚ©Ø±Ø§Ø±",
    min_value=100, max_value=1000, value=300, step=50
)

random_state = st.sidebar.slider(
    "Ù…Ù‚Ø¯Ø§Ø± ØªØµØ§Ø¯ÙÛŒ",
    min_value=0, max_value=100, value=42, step=1
)

def perform_clustering(data, n_clusters, max_iter, random_state):
    features = ['Recency', 'Frequency', 'Monetary']
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
    if not all(col in data.columns for col in features):
        st.error("âŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ù†Ø¯!")
        return data, None, None
    # Ø­Ø°Ù Ù…Ù‚Ø§Ø¯ÛŒØ± NaN
    data = data.dropna(subset=features)
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(data[features])
    kmeans = KMeans(
        n_clusters=n_clusters,
        max_iter=max_iter,
        random_state=random_state,
        n_init=10
    )
    clusters = kmeans.fit_predict(scaled_data)
    data['Cluster'] = clusters
    silhouette_avg = silhouette_score(scaled_data, clusters) if len(data) > 1 else None
    return data, silhouette_avg, kmeans.cluster_centers_

clustered_df, silhouette_avg, centers = perform_clustering(
    rfm_df, n_clusters, max_iter, random_state
)

# ================== Ø¨Ø®Ø´ Ûµ: Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ ==================
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ",
    "ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§",
    "ğŸ¯ ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§",
    "ğŸ† Ø±Ù†Ú©â€ŒØ¨Ù†Ø¯ÛŒ",
    "ğŸ’¾ Ø®Ø±ÙˆØ¬ÛŒ"
])

with tab1:
    st.header("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ ØªØ­Ù„ÛŒÙ„")
    
    # Ø¯ÛŒØ¨Ø§Ú¯: Ù†Ù…Ø§ÛŒØ´ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ
    st.write("**Ø¯ÛŒØ¨Ø§Ú¯ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§:**")
    st.write(f"ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù†: {len(clustered_df)}")
    st.write(f"ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§: {n_clusters}")
    st.write(f"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Recency: {clustered_df['Recency'].mean() if not clustered_df.empty else 'Ù†Ø§Ù…Ø¹ØªØ¨Ø±'}")
    st.write(f"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Frequency: {clustered_df['Frequency'].mean() if not clustered_df.empty else 'Ù†Ø§Ù…Ø¹ØªØ¨Ø±'}")
    st.write(f"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Monetary: {clustered_df['Monetary'].mean() if not clustered_df.empty else 'Ù†Ø§Ù…Ø¹ØªØ¨Ø±'}")
    st.write(f"Ú©Ù„ Monetary: {clustered_df['Monetary'].sum() if not clustered_df.empty else 'Ù†Ø§Ù…Ø¹ØªØ¨Ø±'}")
    st.write(f"Silhouette Score: {silhouette_avg if silhouette_avg is not None else 'Ù†Ø§Ù…Ø¹ØªØ¨Ø±'}")
    st.write(f"ØªÙˆØ²ÛŒØ¹ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§: {clustered_df['Cluster'].value_counts().to_dict() if not clustered_df.empty else 'Ù†Ø§Ù…Ø¹ØªØ¨Ø±'}")
    
    # Ù†Ù…Ø§ÛŒØ´ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
    if clustered_df.empty:
        st.error("âŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø®Ø§Ù„ÛŒ Ù‡Ø³ØªÙ†Ø¯! Ù„Ø·ÙØ§Ù‹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
    else:
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(label="ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù†", value=str(len(clustered_df)) if len(clustered_df) > 0 else "0")
            st.metric(label="ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§", value=str(n_clusters))
        
        with col2:
            avg_r = clustered_df['Recency'].mean()
            avg_f = clustered_df['Frequency'].mean()
            st.metric(label="Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Recency", value=f"{avg_r:.1f} Ø±ÙˆØ²" if not pd.isna(avg_r) else "Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
            st.metric(label="Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Frequency", value=f"{avg_f:.1f}" if not pd.isna(avg_f) else "Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
        
        with col3:
            avg_m = clustered_df['Monetary'].mean()
            total_m = clustered_df['Monetary'].sum()
            st.metric(label="Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Monetary", value=f"{avg_m:,.0f}" if not pd.isna(avg_m) else "Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
            st.metric(label="Ú©Ù„ Monetary", value=f"{total_m:,.0f}" if not pd.isna(total_m) else "Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
        
        with col4:
            st.metric(label="Silhouette Score", value=f"{silhouette_avg:.3f}" if silhouette_avg is not None else "Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
            cluster_counts = clustered_df['Cluster'].value_counts()
            if not cluster_counts.empty:
                st.metric(label="Ø¨Ø²Ø±Ú¯ØªØ±ÛŒÙ† Ø®ÙˆØ´Ù‡", value=f"{cluster_counts.idxmax()} ({cluster_counts.max()})")
            else:
                st.metric(label="Ø¨Ø²Ø±Ú¯ØªØ±ÛŒÙ† Ø®ÙˆØ´Ù‡", value="Ù†Ø§Ù…Ø¹ØªØ¨Ø±")

with tab2:
    st.header("ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        score_dist = clustered_df['RFM_Score'].value_counts().head(10)
        fig_scores = px.bar(
            x=score_dist.values, y=score_dist.index,
            orientation='h', title='Û±Û° Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±ØªØ± RFM',
            labels={'x': 'ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù†', 'y': 'Ø§Ù…ØªÛŒØ§Ø² RFM'},
            color_discrete_sequence=['#00A8B5']
        )
        fig_scores.update_layout(
            plot_bgcolor='#FFFFFF',
            paper_bgcolor='#FFFFFF',
            font=dict(family="Vazir", size=12, color="#1A2E4A"),
            title_font=dict(size=18, family="Vazir", color="#1A2E4A")
        )
        st.plotly_chart(fig_scores, use_container_width=True)
    
    with col2:
        cluster_dist = clustered_df['Cluster'].value_counts()
        fig_clusters = px.pie(
            values=cluster_dist.values, names=cluster_dist.index,
            title='ØªÙˆØ²ÛŒØ¹ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨ÛŒÙ† Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§',
            color_discrete_sequence=px.colors.qualitative.Pastel
        )
        fig_clusters.update_layout(
            plot_bgcolor='#FFFFFF',
            paper_bgcolor='#FFFFFF',
            font=dict(family="Vazir", size=12, color="#1A2E4A"),
            title_font=dict(size=18, family="Vazir", color="#1A2E4A")
        )
        st.plotly_chart(fig_clusters, use_container_width=True)
    
    st.subheader("ğŸ“Š Ù†Ù…ÙˆØ¯Ø§Ø± Ù¾Ø±Ø§Ú©Ù†Ø¯Ú¯ÛŒ")
    col_x, col_y, col_color = st.columns(3)
    
    with col_x:
        x_axis = st.selectbox("Ù…Ø­ÙˆØ± X", ['Recency', 'Frequency', 'Monetary'], key='x_axis')
    with col_y:
        y_axis = st.selectbox("Ù…Ø­ÙˆØ± Y", ['Recency', 'Frequency', 'Monetary'], key='y_axis')
    with col_color:
        color_by = st.selectbox("Ø±Ù†Ú¯ Ø¨Ø± Ø§Ø³Ø§Ø³", ['Cluster', 'R_Score', 'F_Score', 'M_Score'], key='color_by')
    
    fig_scatter = px.scatter(
        clustered_df, x=x_axis, y=y_axis, color=color_by,
        title=f'{y_axis} Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ {x_axis}',
        hover_data=['RFM_Score', 'CustomerID'],
        size='Monetary' if 'Monetary' not in [x_axis, y_axis] else None,
        color_discrete_sequence=px.colors.qualitative.Set2
    )
    fig_scatter.update_layout(
        plot_bgcolor='#FFFFFF',
        paper_bgcolor='#FFFFFF',
        font=dict(family="Vazir", size=12, color="#1A2E4A"),
        title_font=dict(size=18, family="Vazir", color="#1A2E4A")
    )
    st.plotly_chart(fig_scatter, use_container_width=True)

with tab3:
    st.header("ğŸ¯ ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§")
    
    cluster_stats = clustered_df.groupby('Cluster').agg({
        'Recency': ['mean', 'std', 'count'],
        'Frequency': ['mean', 'std'],
        'Monetary': ['mean', 'std', 'sum'],
        'R_Score': 'mean',
        'F_Score': 'mean',
        'M_Score': 'mean'
    }).round(2)
    
    st.dataframe(cluster_stats, use_container_width=True)
    
    st.subheader("ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ Ø¨ÛŒÙ† Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§")
    selected_metrics = st.multiselect(
        "Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡",
        ['Recency', 'Frequency', 'Monetary'],
        default=['Recency', 'Frequency', 'Monetary']
    )
    
    if selected_metrics:
        fig_comparison = go.Figure()
        for metric in selected_metrics:
            fig_comparison.add_trace(go.Box(
                y=clustered_df[metric], x=clustered_df['Cluster'],
                name=metric, boxpoints='outliers'
            ))
        
        fig_comparison.update_layout(
            title='Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ Ø¨ÛŒÙ† Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§',
            plot_bgcolor='#FFFFFF',
            paper_bgcolor='#FFFFFF',
            font=dict(family="Vazir", size=12, color="#1A2E4A"),
            title_font=dict(size=18, family="Vazir", color="#1A2E4A")
        )
        st.plotly_chart(fig_comparison, use_container_width=True)

with tab4:
    st.header("ğŸ† Ø±Ù†Ú©â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†")
    
    rank_by = st.selectbox(
        "Ø±Ù†Ú©â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³:",
        ['Monetary', 'Frequency', 'Recency', 'RFM_Score'],
        index=0
    )
    
    n_top = st.slider("ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù† Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡", 10, 100, 20, 5)
    
    ranked_df = clustered_df.nlargest(n_top, rank_by)
    
    st.dataframe(
        ranked_df[[
            'CustomerID', 'Recency', 'Frequency', 'Monetary',
            'R_Score', 'F_Score', 'M_Score', 'RFM_Score', 'Cluster'
        ]].style.background_gradient(
            subset=['Monetary', 'Frequency'],
            cmap='YlOrBr'
        ),
        use_container_width=True,
        height=600
    )

with tab5:
    st.header("ğŸ’¾ Ø®Ø±ÙˆØ¬ÛŒ Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“Š Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡")
        st.dataframe(clustered_df.head(), use_container_width=True)
        
        csv = clustered_df.to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (CSV)",
            data=csv,
            file_name=f"rfm_clusters_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv"
        )
    
    with col2:
        st.subheader("ğŸ“ˆ Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„")
        report = f"""
# ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ RFM Ùˆ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
ØªØ§Ø±ÛŒØ® ØªÙˆÙ„ÛŒØ¯: {datetime.now().strftime("%Y-%m-%d %H:%M")}

## ğŸ“ˆ Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
- ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù†: {len(clustered_df):,}
- ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§: {n_clusters}
- Ú©ÛŒÙÛŒØª Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (Silhouette Score): {silhouette_avg if silhouette_avg is not None else 'Ù†Ø§Ù…Ø¹ØªØ¨Ø±'}

## ğŸ¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡
- Ú†Ø§Ø±Ú©â€ŒÙ‡Ø§ÛŒ Recency: {r_params}
- Ú†Ø§Ø±Ú©â€ŒÙ‡Ø§ÛŒ Frequency: {f_params}
- Ú†Ø§Ø±Ú©â€ŒÙ‡Ø§ÛŒ Monetary: {m_params}
- ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§: {n_clusters}
- ØªØ¹Ø¯Ø§Ø¯ ØªÚ©Ø±Ø§Ø±: {max_iter}

## ğŸ“Š Ù†ØªØ§ÛŒØ¬ Ú©Ù„ÛŒØ¯ÛŒ
- Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Recency: {clustered_df['Recency'].mean():.1f} Ø±ÙˆØ²
- Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Frequency: {clustered_df['Frequency'].mean():.1f}
- Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Monetary: {clustered_df['Monetary'].mean():,.0f}
- Ú©Ù„ Ø§Ø±Ø²Ø´ Monetary: {clustered_df['Monetary'].sum():,.0f}

## ğŸª ØªÙˆØ²ÛŒØ¹ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§
{clustered_df['Cluster'].value_counts().to_string()}

## ğŸ† Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ø±ØªØ±
{clustered_df.nlargest(5, 'Monetary')[['CustomerID', 'Recency', 'Frequency', 'Monetary', 'RFM_Score']].to_string()}
"""
        st.text_area("Ú¯Ø²Ø§Ø±Ø´ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡:", report, height=300)
        st.download_button(
            label="ğŸ“„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú¯Ø²Ø§Ø±Ø´ (TXT)",
            data=report,
            file_name=f"rfm_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M')}.txt",
            mime="text/plain"
        )

# ================== Ø¨Ø®Ø´ Û¶: Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø§ÛŒÛŒÙ† ØµÙØ­Ù‡ ==================
st.markdown("---")
st.markdown("""
**ğŸ¯ Ø±Ø§Ù‡Ù†Ù…Ø§:**
- Ø§Ø² Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ± Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
- Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ ØµÙˆØ±Øª Ø²Ù†Ø¯Ù‡ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
- Ø§Ø² ØªØ¨â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
- Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯

**ğŸ“ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ:** Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¨Ø§ Ù…Ø§ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯
**ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡:** ØªÛŒÙ… ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ xAI
""")

st.sidebar.info("â„¹ï¸ Ø¨Ø§ ØªØºÛŒÛŒØ± Ù‡Ø± Ù¾Ø§Ø±Ø§Ù…ØªØ±ØŒ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯")
